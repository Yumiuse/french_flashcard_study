# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import requests
import math
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
import os, sys

# ãƒ•ã‚©ãƒ«ãƒ€ç§»å‹•æ™‚ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‚ç…§ã‚’æ­£ã—ãã™ã‚‹ãŸã‚
sys.path.insert(0, os.path.dirname(__file__))

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if 'index' not in st.session_state:
    st.session_state.index = 0
    st.session_state.flip = True
    st.session_state.active_feedback = None
    st.session_state.feedback_message = ""
    st.session_state.review_count = 0
    st.session_state.next_review_time_1 = None
    st.session_state.next_review_time_2 = None
    st.session_state.next_review_time_3 = None

# â”€â”€ Ebbinghaus ãƒ¢ãƒ‡ãƒ«ã®å®šæ•°å®šç¾© â”€â”€
RECALL_THRESHOLD = 0.8     # å¿˜å´æ›²ç·šã®é–¾å€¤ï¼ˆ80%ä¿æŒç‡ã§å†ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰
DEFAULT_STABILITY = 2.0    # åˆæœŸå®‰å®šåº¦ Sï¼ˆæ—¥ï¼‰
STABILITY_FACTORS = {
    "è¦šãˆãŸï¼ğŸŸ¢":    1.3,   # å®Œå…¨æ­£ç­”ãªã‚‰å®‰å®šåº¦ã‚’ 1.3 å€
    "ã†ã‚‹è¦šãˆğŸŸ¡":    1.0,   # ã‚„ã‚„æ›–æ˜§ãªã‚‰ãã®ã¾ã¾
    "è¦šãˆã¦ã„ãªã„ï¼ğŸ”´": 0.7  # ä¸æ­£è§£ãªã‚‰å®‰å®šåº¦ã‚’ 0.7 å€
}

def compute_next_times(feedback_key: str,
                       last_review: datetime = None,
                       initial_stability: float = None):
    """
    Ebbinghaus ã®å¿˜å´æ›²ç·š R(t)=e^{-t/S} ã‹ã‚‰æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼“å›åˆ†ã‚’è¨ˆç®—ã€‚
    """
    now = datetime.now(ZoneInfo("Asia/Tokyo")) if last_review is None else last_review
    S = initial_stability if initial_stability is not None else DEFAULT_STABILITY

    times = []
    for _ in range(3):
        t_days = -S * math.log(RECALL_THRESHOLD)
        next_time = now + timedelta(days=t_days)
        times.append(next_time)
        now = next_time
        factor = STABILITY_FACTORS.get(feedback_key, STABILITY_FACTORS["ã†ã‚‹è¦šãˆğŸŸ¡"])
        S *= factor

    return times

# ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¸ˆã¿ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰
@st.cache_data
def load_data():
    return pd.read_csv('data/mettre_fin_Lexique_translated_v6w_ä¿®æ­£æ¸ˆã¿.csv') \
             .sample(frac=1).reset_index(drop=True)

df = load_data()

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€æ—¥æ™‚åˆ—ã‚’ datetime å‹ã«å¤‰æ›
@st.cache_data
def load_feedback():
    try:
        fb = pd.read_csv('data/feedback.csv', parse_dates=[
            "next_review_time_1",
            "next_review_time_2",
            "next_review_time_3"
        ])
        return fb
    except FileNotFoundError:
        # feedback.csv ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã® DataFrame ã‚’è¿”ã™
        cols = [
            "user_id", "card_id", "feedback", "feedback_time", "review_count",
            "next_review_time_1", "next_review_time_2", "next_review_time_3",
            "next_review1", "next_review2", "next_review3", "recorded_at"
        ]
        return pd.DataFrame(columns=cols)

# æœŸé™ãŒåˆ°æ¥ã—ã¦ã„ã‚‹ã‚«ãƒ¼ãƒ‰ ID ã®é›†åˆã‚’è¿”ã™
def get_due_card_ids():
    fb = load_feedback()
    now = datetime.now(ZoneInfo("Asia/Tokyo"))
    due_ids = set()
    for _, row in fb.iterrows():
        for n in (1, 2, 3):
            col_time = f"next_review_time_{n}"
            col_flag = f"next_review{n}"
            if pd.notnull(row.get(col_time)) and row[col_time] <= now and row.get(col_flag, 0) == 1:
                due_ids.add(row["card_id"])
                break
    return due_ids

# æ–°è¦ã‚«ãƒ¼ãƒ‰ï¼ˆæœªãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰ã®ã‚«ãƒ¼ãƒ‰ ID ã®é›†åˆã‚’è¿”ã™
def get_new_card_ids():
    fb = load_feedback()
    reviewed = set(fb["card_id"].tolist())
    all_ids = set(df["id"].tolist())
    return all_ids - reviewed

# ã‚«ãƒ¼ãƒ‰ã‚’é¸æŠã™ã‚‹é–¢æ•°ï¼ˆæœŸé™ã‚«ãƒ¼ãƒ‰ > æ–°è¦ã‚«ãƒ¼ãƒ‰ > ã‚·ãƒ£ãƒƒãƒ•ãƒ«é †ï¼‰
def select_card(index: int):
    due_ids = get_due_card_ids()
    new_ids = get_new_card_ids()

    if due_ids:
        df_due = df[df["id"].isin(due_ids)].reset_index(drop=True)
        return df_due.iloc[index % len(df_due)]
    elif new_ids:
        df_new = df[df["id"].isin(new_ids)].reset_index(drop=True)
        return df_new.iloc[index % len(df_new)]
    else:
        # ã™ã¹ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿ã‹ã¤æœŸé™ã‚«ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯ã€ã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¸ˆã¿ df ã‹ã‚‰é †ç•ªã«å›ã™
        return df.iloc[index % len(df)]

# Streamlit ç”¨ CSS
st.markdown("""
<style>
h1 {
  margin-top: 0.4rem !important;
  margin-bottom: 0.5rem !important;
}
.block-container {
  padding-top: 1rem !important;
}
.custom-font {
  font-size: 15px;
}
.custom-card {
  position: relative;
  height: 50vh;
  width: 60vw;
  background-color: rgba(255, 250, 205, 0.8);
  display: flex;
  justify-content: center;
  align-items: center;
  margin: auto;
  border-radius: 10px;
  padding: 20px;
  font-size: 24px;
  color: black;
  font-family: 'Arial', sans-serif;
  font-weight: bold;
  letter-spacing: 2px;
  overflow: auto;
}
.level-text {
  color: #808080;
}
div.stButton > button {
  position: absolute;
  top: -30px;
  right: 10px;
  height: 50px;
  width: 200px;
  font-size: 24px;
  background-color: #40e0d0;
  color: white;
  border-radius: 10px;
  border: none;
  cursor: pointer;
  z-index: 10;
}
div.stButton > button:hover {
  background-color: #20b2aa;
}
</style>
<div class='custom-font'>ã‚¹ãƒšãƒ¼ã‚¹ãƒ‰ãƒ¬ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³</div>
""", unsafe_allow_html=True)

# ãƒ˜ãƒƒãƒ€ãƒ¼
st.markdown("""
<h1 style="font-size:1.7rem; font-weight:bold; margin-bottom:0.5rem;">
  ãƒ•ãƒ©ãƒ³ã‚¹èªãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰å­¦ç¿’
</h1>
""", unsafe_allow_html=True)

# --- ã‚«ãƒ¼ãƒ‰ã®å–å¾— ---
card = select_card(st.session_state.index)
st.session_state.card_id = card["id"]

# --- ã‚«ãƒ¼ãƒ‰è¡¨é¢ãƒ»è£é¢ã®è¡¨ç¤º ---
if st.session_state.flip:
    # è¡¨é¢ï¼šå˜èªãƒ»èª­ã¿ãƒ»ãƒ¬ãƒ™ãƒ«
    word_surface  = card["ortho"]
    lemma_surface = card.get("lemme", "")
    phon_surface  = card.get("phon", "")
    # ãƒ¬ãƒ™ãƒ«åˆ¤å®šAPI ã‚’å‘¼ã³å‡ºã™ï¼ˆãƒãƒ¼ãƒˆ 8014ï¼‰
    try:
        resp = requests.post(
            "http://127.0.0.1:8014/predict/",
            json={"lemme": word_surface, "card_id": int(st.session_state.card_id)}
        )
        resp.raise_for_status()
        level_surface = resp.json().get("level", "æœªå®šç¾©")
    except requests.RequestException as e:
        level_surface = f"ãƒ¬ãƒ™ãƒ«APIã‚¨ãƒ©ãƒ¼: {e}"

    content_html = f"""
    <div style='text-align: center;'>
      <div style="font-size: 28px; font-weight: bold; margin-bottom: 4px;">
        {word_surface}
      </div>
      <div style="color: gray; font-style: italic; font-size: smaller; margin-bottom: 2px;">
        {("/" + phon_surface + "/") if phon_surface else ""}
      </div>
      <div style="color: gray; font-size: smaller; margin-bottom: 6px;">
        ({lemma_surface})
      </div>
      <span class='level-text' style="font-size: smaller;">
        {level_surface}
      </span>
    </div>
    """
else:
    # è£é¢ï¼šç¿»è¨³ãƒ»æ–‡æ³•æƒ…å ±
    try:
        resp = requests.post(
            "http://127.0.0.1:8000/translate/",
            json={"word": card["ortho"]}
        )
        resp.raise_for_status()
        translation = resp.json().get("translation", "ç¿»è¨³APIã‚¨ãƒ©ãƒ¼")
    except requests.RequestException as e:
        translation = f"ç¿»è¨³APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {e}"

    pos = str(card.get("cgram_jp", "")).strip()
    inflection = str(card.get("infover_full_translation", "")).strip()
    gender = str(card.get("genre_jp", "")).strip()

    display_parts = []
    if translation:
        parts = [t.strip() for t in translation.split(",")]
        formatted = "<br>".join([f"<b>{t}</b>" for t in parts])
        display_parts.append(formatted)

    if pos:
        display_parts.append(f"ã€å“è©ã€‘ {pos}")
    if inflection and inflection.lower() != "nan":
        display_parts.append(f"ã€æ´»ç”¨ãªã©ã€‘ {inflection}")
    if gender and gender.lower() not in ("nan", "nun"):
        display_parts.append(f"ã€æ€§ã€‘ {gender}")

    inner_html = "<br>".join(display_parts)
    content_html = f"<div style='text-align: left;'>{inner_html}</div>"

# ã‚«ãƒ¼ãƒ‰å…¨ä½“ã‚’è¡¨ç¤º
st.markdown(f"<div class='custom-card'>{content_html}</div>", unsafe_allow_html=True)

# --- Flipãƒœã‚¿ãƒ³ã®å‡¦ç† ---
feedback_options = {
    "è¦šãˆãŸï¼ğŸŸ¢":    {"label": "è¦šãˆãŸï¼ğŸŸ¢",    "message": "ã‹ã‚“ãºãã¿ãŸã„ã ã­ï¼"},
    "ã†ã‚‹è¦šãˆğŸŸ¡":    {"label": "ã†ã‚‹è¦šãˆğŸŸ¡",  "message": "ã‚‚ã†ä¸€åº¦ï¼ã‚ã¨å°‘ã—ï¼"},
    "è¦šãˆã¦ã„ãªã„ï¼ğŸ”´": {"label": "è¦šãˆã¦ã„ãªã„ï¼ğŸ”´", "message": "é ‘å¼µã‚ã†ï¼å°‘ã—ç·´ç¿’ãŒå¿…è¦ã ã­ã€‚"}
}

cols = st.columns(len(feedback_options))
button_pressed = None

for i, (key, opt) in enumerate(feedback_options.items()):
    disabled = (
        st.session_state.active_feedback is not None
        and st.session_state.active_feedback != key
    )
    if cols[i].button(opt["label"], key=f"fb_{key}", disabled=disabled):
        button_pressed = key

if button_pressed is not None:
    if st.session_state.active_feedback is None:
        st.session_state.active_feedback = button_pressed
        st.session_state.feedback_message = feedback_options[button_pressed]["message"]
        st.session_state.review_count += 1

        next1, next2, next3 = compute_next_times(button_pressed)
        payload = {
            "user_id":      "user1",
            "card_id":      int(st.session_state.card_id),
            "feedback":     str(button_pressed),
            "feedback_time": datetime.now(ZoneInfo("Asia/Tokyo")).isoformat(),
            "review_count": int(st.session_state.review_count),
            "next_review_time_1": next1.isoformat(),
            "next_review_time_2": next2.isoformat(),
            "next_review_time_3": next3.isoformat(),
            "next_review1": True,
            "next_review2": True,
            "next_review3": True
        }
        try:
            resp = requests.post("http://127.0.0.1:8014/feedback/", json=payload)
            resp.raise_for_status()
            st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã—ã¾ã—ãŸï¼")
        except requests.HTTPError:
            st.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²å¤±æ•—: {resp.status_code} {resp.text}")

    st.session_state.flip = False
    st.rerun()

# --- æœ€æ–°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’è¡¨ç¤º ---
st.write("\n")
st.write("\n")

try:
    df_lexique = pd.read_csv('data/mettre_fin_Lexique_translated_v6w_ä¿®æ­£æ¸ˆã¿.csv', dtype={"level": int})
except Exception as e:
    st.error(f"èªå½™ CSV ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    df_lexique = pd.DataFrame()

with st.expander("â–¶ï¸ æœ€æ–°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’è¡¨ç¤º"):
    try:
        df_fb = load_feedback()
        if (
            not df_lexique.empty
            and "card_id" in df_fb.columns
            and "id" in df_lexique.columns
            and "ortho" in df_lexique.columns
        ):
            merged = pd.merge(
                df_fb,
                df_lexique[["id", "ortho"]],
                left_on="card_id",
                right_on="id",
                how="left"
            )
            merged = merged.drop(columns=["id"])
            cols = merged.columns.tolist()
            cols = ["ortho"] + [c for c in cols if c != "ortho"]
            merged = merged[cols]
            st.dataframe(merged.tail(10))
        else:
            st.warning("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã¾ãŸã¯èªå½™ãƒ‡ãƒ¼ã‚¿ã«å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            st.dataframe(df_fb.tail(10))
    except Exception as e:
        st.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ CSV ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
